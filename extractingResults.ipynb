{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abfc9617",
   "metadata": {},
   "source": [
    "<h1>Extracting results</h1>\n",
    "<p>Here we extract data required to plot results from the data generated by ... </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a19b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d724d",
   "metadata": {},
   "source": [
    "<h3>collecting data</h3>\n",
    "<p>The following function renames some columns, recodes some True/False columns using string values, and outputs a subset of columns into a CSV file that can be used for plotting</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfba1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_core_results(df):\n",
    "    df[\"train_size\"] = [\n",
    "        float(json.loads(holdouts_kwargs)[\"train_size\"])\n",
    "        for holdouts_kwargs in df.holdouts_kwargs\n",
    "    ]\n",
    "\n",
    "    df[\"features_names\"] = [\n",
    "        json.loads(edge_feature.replace(\"'\", \"\\\"\"))[0] if pd.notna(edge_feature) else feature_name\n",
    "        for feature_name, edge_feature in zip(\n",
    "            df.features_names,\n",
    "            df[\"('model_parameters', 'edge_features')\"]\n",
    "        )\n",
    "    ]\n",
    "    df[\"evaluation_negative_sampling_method\"] = [\n",
    "    \"DANS\"\n",
    "    if use_scale_free_distribution\n",
    "    else \"UNS\"\n",
    "    for use_scale_free_distribution in df.use_scale_free_distribution\n",
    "    ]\n",
    "    df = df[\n",
    "        [\n",
    "            pd.isna(a) or a == b\n",
    "            for a, b in zip(\n",
    "                df[\"('features_parameters', 'use_scale_free_distribution')\"],\n",
    "                df[\"('model_parameters', 'use_scale_free_distribution')\"],\n",
    "            )\n",
    "        ]\n",
    "    ]\n",
    "    df[\"model_negative_examples\"] = [\n",
    "     \"{training}\".format(training=(\"DANS\" if f else \"UNS\"))\n",
    "        for f in df[\"('features_parameters', 'use_scale_free_distribution')\"]\n",
    "    ]\n",
    "    columns = [\"evaluation_mode\", \"features_names\",\"evaluation_negative_sampling_method\",\n",
    "               \"model_negative_examples\", \"accuracy\",  \"balanced_accuracy\", \n",
    "               \"false_discovery_rate\",\"matthews_correlation_coefficient\",\n",
    "           \"precision\", \"recall\", \"specificity\", \"f1_score\", \"auroc\", \"auprc\"]\n",
    "    return df[columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indirectory = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd20a53",
   "metadata": {},
   "source": [
    "<h3>STRING Protein-Protein Association data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f65936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv(\n",
    "        path,\n",
    "        index_col=0\n",
    "    )\n",
    "    for path in glob(f\"{indirectory}/experiments/Edge Prediction/HomoSapiens/holdout_*/*.csv.gz\")\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_results = extract_core_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46358db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5557e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_results.to_csv(\"string_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8053fa8",
   "metadata": {},
   "source": [
    "<h3>SLI synthetic lethality results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv(\n",
    "        path,\n",
    "        index_col=0\n",
    "    )\n",
    "    for path in glob(f\"{indirectory}/experiments/Edge Prediction/(SLDB | HomoSapiens)/holdout_*/*.csv.gz\")\n",
    "]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02421323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_results = extract_core_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_results.to_csv(\"sli_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6bcb0",
   "metadata": {},
   "source": [
    "<H1>Aggregating Results</H1>\n",
    "<p>Here, we calculate the mean and standard deviation of the\n",
    "    balanced accuracy, false discovery rate, matthews correlation coefficient,\n",
    "    F1 score, AUROC, and AUPRC.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e90040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(df):\n",
    "    \"\"\"\n",
    "    df should be one of string_results or sli_results\n",
    "    \"\"\"\n",
    "    # We are just interested in the following seven graph/random walk methods\n",
    "    graph_methods = {'First-order LINE', 'DeepWalk SkipGram', 'Walklets CBOW', 'HOPE',\n",
    "                 'Second-order LINE','DeepWalk CBOW',    'Walklets SkipGram'}\n",
    "    df = df[df['features_names'].isin(graph_methods)]\n",
    "    # Rename columns for conciseness\n",
    "    df =  df.rename(columns={\"evaluation_negative_sampling_method\": \"evaluation\", \n",
    "                   \"evaluation_mode\": \"mode\",\"features_names\":\"methods\"}, errors=\"raise\")\n",
    "    # Define the columns that we want to calculate mean and std def for\n",
    "    evaluation_d = {'balanced_accuracy':['mean','std'],\n",
    "               'false_discovery_rate':['mean','std'], \n",
    "               'matthews_correlation_coefficient':['mean','std'], \n",
    "               'f1_score':['mean','std'], \n",
    "               'auroc':['mean','std'], \n",
    "               'auprc':['mean','std']}\n",
    "    # Calculate mean and standard dev\n",
    "    df2 =  df.groupby(['methods','mode','evaluation']).agg(evaluation_d).reset_index()\n",
    "    # Make a new column for convenience in planning\n",
    "    df2[\"approach\"] = df2[\"evaluation\"] + \" (\" + df2[\"mode\"] + \")\"\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3840214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns from tuples to simple strings for readability\n",
    "columns = [\"methods\",'mode','evaluation', \"balanced_acc.mean\",\"balanced_acc.std\",\"FDR.mean\",\n",
    "                    \"FDR.std\", \"MCC.mean\", \"MCC.std\", \"F1.mean\", \"F1.std\", \"AUROC.mean\",\n",
    "                     \"AUROC.std\", \"AUPRC.mean\",\"AUPRC.std\", \"approach\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ef5ed",
   "metadata": {},
   "source": [
    "<h3>SLI</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106884cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_stats = get_mean_and_std(sli_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b55544",
   "metadata": {},
   "outputs": [],
   "source": [
    "sli_stats.columns = columns\n",
    "sli_stats.to_csv(\"sli_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f705d4",
   "metadata": {},
   "source": [
    "<h3>STRING</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fec4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_stats = get_mean_and_std(string_results)\n",
    "string_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_stats.columns = columns\n",
    "string_stats.to_csv(\"string_stats.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nesvenv",
   "language": "python",
   "name": "nesvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
